{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1770c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_elo_ratings = pd.read_csv('../data/processed/player_elo_ratings.csv')\n",
    "df_validation = pd.read_csv('../data/processed/atp_matches_2025.csv')\n",
    "df_test = pd.read_csv('../data/processed/wimbledon_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f82b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Prediction Function \"\"\"\n",
    "\n",
    "def predict_match_winner(player1, player2, surface=None, elo_ratings_df=None):\n",
    "    \"\"\"\n",
    "    Predict the winner of a match based on Elo ratings\n",
    "    \n",
    "    Args:\n",
    "        player1: Name of first player\n",
    "        player2: Name of second player\n",
    "        surface: Surface type ('Hard', 'Clay', 'Grass') - if None, uses overall Elo\n",
    "        elo_ratings_df: DataFrame with Elo ratings\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (predicted_winner, win_probability, player1_elo, player2_elo)\n",
    "    \"\"\"\n",
    "    # Get player ratings\n",
    "    player1_data = elo_ratings_df[elo_ratings_df['player'] == player1]\n",
    "    player2_data = elo_ratings_df[elo_ratings_df['player'] == player2]\n",
    "    \n",
    "    # If players not found, return None\n",
    "    if len(player1_data) == 0 or len(player2_data) == 0:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Determine which Elo column to use\n",
    "    if surface == 'Hard':\n",
    "        elo_col = 'elo_hard'\n",
    "    elif surface == 'Clay':\n",
    "        elo_col = 'elo_clay'\n",
    "    elif surface == 'Grass':\n",
    "        elo_col = 'elo_grass'\n",
    "    else:\n",
    "        elo_col = 'elo_overall'\n",
    "    \n",
    "    player1_elo = player1_data[elo_col].values[0]\n",
    "    player2_elo = player2_data[elo_col].values[0]\n",
    "    \n",
    "    # Calculate win probability using Elo formula\n",
    "    expected_score_p1 = 1 / (1 + 10 ** ((player2_elo - player1_elo) / 400))\n",
    "    \n",
    "    # Predict winner\n",
    "    predicted_winner = player1 if expected_score_p1 > 0.5 else player2\n",
    "    win_probability = expected_score_p1 if expected_score_p1 > 0.5 else 1 - expected_score_p1\n",
    "    \n",
    "    return predicted_winner, win_probability, player1_elo, player2_elo\n",
    "\n",
    "\n",
    "def evaluate_predictions(matches_df, elo_ratings_df, surface=None, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Evaluate prediction accuracy on a set of matches\n",
    "    \n",
    "    Args:\n",
    "        matches_df: DataFrame with columns 'winner_name', 'loser_name'\n",
    "        elo_ratings_df: DataFrame with Elo ratings\n",
    "        surface: Surface type (if None, uses overall Elo)\n",
    "        dataset_name: Name for reporting\n",
    "    \n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for idx, row in matches_df.iterrows():\n",
    "        winner = row['winner_name']\n",
    "        loser = row['loser_name']\n",
    "        \n",
    "        # Actual winner is the winner_name column\n",
    "        actual_winner = winner\n",
    "        \n",
    "        # Predict winner (we treat winner_name as player1)\n",
    "        predicted_winner, win_prob, winner_elo, loser_elo = predict_match_winner(\n",
    "            winner, loser, surface=surface, elo_ratings_df=elo_ratings_df\n",
    "        )\n",
    "        \n",
    "        # Skip if prediction couldn't be made\n",
    "        if predicted_winner is None:\n",
    "            continue\n",
    "        \n",
    "        # Check if prediction is correct\n",
    "        correct = predicted_winner == actual_winner\n",
    "        \n",
    "        predictions.append({\n",
    "            'winner_name': winner,\n",
    "            'loser_name': loser,\n",
    "            'predicted_winner': predicted_winner,\n",
    "            'actual_winner': actual_winner,\n",
    "            'correct': correct,\n",
    "            'win_probability': win_prob,\n",
    "            'winner_elo': winner_elo,\n",
    "            'loser_elo': loser_elo,\n",
    "            'elo_diff': abs(winner_elo - loser_elo)\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(predictions)\n",
    "    \n",
    "    if len(results_df) == 0:\n",
    "        print(f\"No predictions could be made for {dataset_name}\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = results_df['correct'].mean()\n",
    "    total_matches = len(results_df)\n",
    "    correct_predictions = results_df['correct'].sum()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{dataset_name} Results\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total matches: {total_matches}\")\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    print(f\"Average win probability: {results_df['win_probability'].mean():.2%}\")\n",
    "    print(f\"Average Elo difference: {results_df['elo_diff'].mean():.1f}\")\n",
    "    \n",
    "    # Accuracy by confidence level\n",
    "    print(f\"\\nAccuracy by confidence level:\")\n",
    "    for threshold in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        confident = results_df[results_df['win_probability'] >= threshold]\n",
    "        if len(confident) > 0:\n",
    "            conf_accuracy = confident['correct'].mean()\n",
    "            print(f\"  Probability >= {threshold:.0%}: {conf_accuracy:.2%} ({len(confident)} matches)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'total_matches': total_matches,\n",
    "        'correct_predictions': correct_predictions,\n",
    "        'results_df': results_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3645fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation Set (ATP 2025) - Overall Elo Results\n",
      "============================================================\n",
      "Total matches: 431\n",
      "Correct predictions: 308\n",
      "Accuracy: 71.46%\n",
      "Average win probability: 70.56%\n",
      "Average Elo difference: 174.4\n",
      "\n",
      "Accuracy by confidence level:\n",
      "  Probability >= 50%: 71.46% (431 matches)\n",
      "  Probability >= 60%: 75.96% (312 matches)\n",
      "  Probability >= 70%: 79.72% (212 matches)\n",
      "  Probability >= 80%: 84.75% (118 matches)\n",
      "  Probability >= 90%: 94.44% (36 matches)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Evaluate on Validation Set (ATP 2025) - Overall Elo \"\"\"\n",
    "\n",
    "validation_results = evaluate_predictions(\n",
    "    df_validation,\n",
    "    df_elo_ratings,\n",
    "    surface=None,\n",
    "    dataset_name=\"Validation Set (ATP 2025) - Overall Elo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560e27af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Test Set (Wimbledon 2025) - Overall Elo Results\n",
      "============================================================\n",
      "Total matches: 30\n",
      "Correct predictions: 19\n",
      "Accuracy: 63.33%\n",
      "Average win probability: 76.72%\n",
      "Average Elo difference: 252.6\n",
      "\n",
      "Accuracy by confidence level:\n",
      "  Probability >= 50%: 63.33% (30 matches)\n",
      "  Probability >= 60%: 70.83% (24 matches)\n",
      "  Probability >= 70%: 76.19% (21 matches)\n",
      "  Probability >= 80%: 73.33% (15 matches)\n",
      "  Probability >= 90%: 100.00% (6 matches)\n",
      "\n",
      "============================================================\n",
      "Test Set (Wimbledon 2025) - Grass Elo Results\n",
      "============================================================\n",
      "Total matches: 30\n",
      "Correct predictions: 19\n",
      "Accuracy: 63.33%\n",
      "Average win probability: 69.94%\n",
      "Average Elo difference: 173.0\n",
      "\n",
      "Accuracy by confidence level:\n",
      "  Probability >= 50%: 63.33% (30 matches)\n",
      "  Probability >= 60%: 70.00% (20 matches)\n",
      "  Probability >= 70%: 80.00% (15 matches)\n",
      "  Probability >= 80%: 71.43% (7 matches)\n",
      "  Probability >= 90%: 100.00% (3 matches)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Evaluate on Test Set (Wimbledon 2025) - Overall Elo \"\"\"\n",
    "\n",
    "test_results_overall = evaluate_predictions(\n",
    "    df_test,\n",
    "    df_elo_ratings,\n",
    "    surface=None,\n",
    "    dataset_name=\"Test Set (Wimbledon 2025) - Overall Elo\"\n",
    ")\n",
    "\"\"\" Evaluate on Test Set (Wimbledon 2025) - Grass Elo \"\"\"\n",
    "\n",
    "test_results_grass = evaluate_predictions(\n",
    "    df_test,\n",
    "    df_elo_ratings,\n",
    "    surface='Grass',\n",
    "    dataset_name=\"Test Set (Wimbledon 2025) - Grass Elo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "325644fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to: ../data/processed/wimbledon_predictions.csv\n",
      "\n",
      "Generated 30 predictions\n",
      "\n",
      "First 10 predictions:\n",
      "                                      matchup round     predicted_winner  \\\n",
      "0      Arthur Rinderknech vs Alexander Zverev  R128     Alexander Zverev   \n",
      "1                 Ethan Quinn vs Henry Searle  R128         Henry Searle   \n",
      "2             Carlos Alcaraz vs Fabio Fognini  R128       Carlos Alcaraz   \n",
      "3  Taylor Fritz vs Giovanni Mpetshi Perricard  R128         Taylor Fritz   \n",
      "4        Kamil Majchrzak vs Matteo Berrettini  R128    Matteo Berrettini   \n",
      "5                Nicolas Jarry vs Holger Rune  R128          Holger Rune   \n",
      "6          Nuno Borges vs Francisco Cerundolo  R128  Francisco Cerundolo   \n",
      "7               Arthur Fery vs Alexei Popyrin  R128       Alexei Popyrin   \n",
      "8          Novak Djokovic vs Alexandre Muller  R128       Novak Djokovic   \n",
      "9          Pedro Martinez vs George Loffhagen  R128       Pedro Martinez   \n",
      "\n",
      "  predicted_win_probability       actual_winner  \n",
      "0                     74.5%  Arthur Rinderknech  \n",
      "1                     54.6%         Ethan Quinn  \n",
      "2                     95.5%      Carlos Alcaraz  \n",
      "3                     81.6%        Taylor Fritz  \n",
      "4                     80.4%     Kamil Majchrzak  \n",
      "5                     85.1%       Nicolas Jarry  \n",
      "6                     66.2%         Nuno Borges  \n",
      "7                     85.0%         Arthur Fery  \n",
      "8                     90.3%      Novak Djokovic  \n",
      "9                     58.8%      Pedro Martinez  \n"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate Wimbledon Predictions CSV \"\"\"\n",
    "\n",
    "def create_predictions_csv(matches_df, elo_ratings_df, surface=None, output_path=None):\n",
    "    \"\"\"\n",
    "    Create a CSV with match predictions\n",
    "    \n",
    "    Args:\n",
    "        matches_df: DataFrame with match data\n",
    "        elo_ratings_df: DataFrame with Elo ratings\n",
    "        surface: Surface type (if None, uses overall Elo)\n",
    "        output_path: Path to save CSV\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with predictions\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for idx, row in matches_df.iterrows():\n",
    "        winner = row['winner_name']\n",
    "        loser = row['loser_name']\n",
    "        round_name = row['round']\n",
    "        \n",
    "        # Actual winner\n",
    "        actual_winner = winner\n",
    "        \n",
    "        # Predict winner (treating winner as player1)\n",
    "        predicted_winner, win_prob, winner_elo, loser_elo = predict_match_winner(\n",
    "            winner, loser, surface=surface, elo_ratings_df=elo_ratings_df\n",
    "        )\n",
    "        \n",
    "        # Skip if prediction couldn't be made\n",
    "        if predicted_winner is None:\n",
    "            continue\n",
    "        \n",
    "        predictions.append({\n",
    "            'matchup': f\"{winner} vs {loser}\",\n",
    "            'round': round_name,\n",
    "            'predicted_winner': predicted_winner,\n",
    "            'predicted_win_probability': f\"{win_prob:.1%}\",\n",
    "            'actual_winner': actual_winner\n",
    "        })\n",
    "    \n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    \n",
    "    if output_path:\n",
    "        predictions_df.to_csv(output_path, index=False)\n",
    "        print(f\"Predictions saved to: {output_path}\")\n",
    "    \n",
    "    return predictions_df\n",
    "\n",
    "# Generate Wimbledon predictions using Overall Elo\n",
    "wimbledon_predictions = create_predictions_csv(\n",
    "    df_test,\n",
    "    df_elo_ratings,\n",
    "    surface=None,  # Use overall Elo\n",
    "    output_path='../data/processed/wimbledon_predictions.csv'\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(wimbledon_predictions)} predictions\")\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(wimbledon_predictions.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
